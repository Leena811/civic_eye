{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Leena811/civic_eye/blob/main/final_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FueWwTAbaZ6g"
      },
      "outputs": [],
      "source": [
        "# 1.1 Enable GPU: Runtime -> Change runtime type -> GPU\n",
        "# 1.2 Run this cell to mount Drive and check GPU + TF\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = '/content/drive/MyDrive/civic_eye_dataset_new'\n",
        "# The four folders (exact names you provided):\n",
        "classes = ['garbage_images','Potholes_images','Sewage_drainage_images','street_light_images']\n"
      ],
      "metadata": {
        "id": "mVin9kgeadyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob\n",
        "for c in classes:\n",
        "    files = []\n",
        "    for ext in ('*.jpg','*.jpeg','*.png'):\n",
        "        files += glob.glob(os.path.join(DATA_DIR, c, ext))\n",
        "    print(f\"{c}: {len(files)} images\")\n"
      ],
      "metadata": {
        "id": "PO_rDXgUax-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import glob\n",
        "\n",
        "filepaths = []\n",
        "labels = []\n",
        "for idx, c in enumerate(classes):\n",
        "    for ext in ('*.jpg','*.jpeg','*.png'):\n",
        "        for f in glob.glob(os.path.join(DATA_DIR, c, ext)):\n",
        "            filepaths.append(f)\n",
        "            labels.append(idx)\n",
        "\n",
        "filepaths = np.array(filepaths)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# 70% train, 30% temp -> then split temp into val & test (50/50 -> 15% each)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    filepaths, labels, stratify=labels, test_size=0.30, random_state=42)\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, stratify=y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "print(\"train, val, test sizes:\", len(X_train), len(X_val), len(X_test))\n",
        "\n"
      ],
      "metadata": {
        "id": "p_nVLWQga2F0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "IMG_SIZE = (224, 224)     # works well with EfficientNetB0\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# augmentation (used only for training)\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "    tf.keras.layers.RandomRotation(0.12),\n",
        "    tf.keras.layers.RandomZoom(0.12),\n",
        "    tf.keras.layers.RandomContrast(0.08),\n",
        "])\n",
        "\n",
        "def decode_resize(path):\n",
        "    image = tf.io.read_file(path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)  # handles jpg/jpeg/png\n",
        "    image = tf.image.resize(image, IMG_SIZE)\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    return image\n",
        "\n",
        "# EfficientNet expects its preprocess_input (scales as needed)\n",
        "preprocess = tf.keras.applications.efficientnet.preprocess_input\n",
        "\n",
        "def process_train(path, label):\n",
        "    image = decode_resize(path)\n",
        "    image = data_augmentation(image)\n",
        "    image = preprocess(image)   # now it's ready for the pretrained model\n",
        "    return image, label\n",
        "\n",
        "def process_eval(path, label):\n",
        "    image = decode_resize(path)\n",
        "    image = preprocess(image)\n",
        "    return image, label\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "train_ds = (train_ds.shuffle(len(X_train))\n",
        "                    .map(lambda x,y: process_train(x,y), num_parallel_calls=AUTOTUNE)\n",
        "                    .batch(BATCH_SIZE)\n",
        "                    .prefetch(AUTOTUNE))\n",
        "\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).map(process_eval, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).map(process_eval, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "xwO8W0jxfHAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import class_weight\n",
        "class_weights_arr = class_weight.compute_class_weight('balanced',\n",
        "                                                     classes=np.unique(y_train),\n",
        "                                                     y=y_train)\n",
        "class_weights = {i: w for i, w in enumerate(class_weights_arr)}\n",
        "print(\"class_weights:\", class_weights)\n"
      ],
      "metadata": {
        "id": "y8I9Nd58fQHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.EfficientNetB0(\n",
        "    include_top=False, weights='imagenet', input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
        "base_model.trainable = False   # freeze for head training\n",
        "\n",
        "inputs = tf.keras.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
        "x = base_model(inputs, training=False)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dropout(0.3)(x)\n",
        "outputs = tf.keras.layers.Dense(len(classes), activation='softmax')(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "sqB4WAUEfYEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint('/content/drive/MyDrive/civic_eye_model_best.keras',\n",
        "                                       save_best_only=True, monitor='val_loss'),\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-7)\n",
        "]\n",
        "\n",
        "initial_epochs = 10\n",
        "history = model.fit(train_ds,\n",
        "                    epochs=initial_epochs,\n",
        "                    validation_data=val_ds,\n",
        "                    class_weight=class_weights,\n",
        "                    callbacks=callbacks)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fmLE9ZNfbaY",
        "outputId": "7efba0b9-2d37-4b50-cbbb-9a56bffc4184"
      },
      "execution_count": 16,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 5s/step - accuracy: 0.3928 - loss: 1.2935 - val_accuracy: 0.8800 - val_loss: 0.5722 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 3s/step - accuracy: 0.8605 - loss: 0.5779 - val_accuracy: 0.9667 - val_loss: 0.2894 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 4s/step - accuracy: 0.9444 - loss: 0.3236 - val_accuracy: 0.9733 - val_loss: 0.1975 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 4s/step - accuracy: 0.9478 - loss: 0.2605 - val_accuracy: 0.9800 - val_loss: 0.1533 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 4s/step - accuracy: 0.9513 - loss: 0.2303 - val_accuracy: 0.9867 - val_loss: 0.1256 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 4s/step - accuracy: 0.9681 - loss: 0.1849 - val_accuracy: 0.9867 - val_loss: 0.1100 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 3s/step - accuracy: 0.9737 - loss: 0.1617 - val_accuracy: 0.9867 - val_loss: 0.0959 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3s/step - accuracy: 0.9637 - loss: 0.1371 - val_accuracy: 0.9867 - val_loss: 0.0856 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 4s/step - accuracy: 0.9657 - loss: 0.1493 - val_accuracy: 0.9867 - val_loss: 0.0813 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 3s/step - accuracy: 0.9650 - loss: 0.1249 - val_accuracy: 0.9867 - val_loss: 0.0719 - learning_rate: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze last N layers of base_model for fine-tuning\n",
        "base_model.trainable = True\n",
        "fine_tune_at = len(base_model.layers) - 30  # you can experiment with this number\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "fine_tune_epochs = 15\n",
        "total_epochs = initial_epochs + fine_tune_epochs\n",
        "\n",
        "history_fine = model.fit(train_ds,\n",
        "                         epochs=total_epochs,\n",
        "                         initial_epoch=history.epoch[-1],\n",
        "                         validation_data=val_ds,\n",
        "                         class_weight=class_weights,\n",
        "                         callbacks=callbacks)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbDgP9p_fi6e",
        "outputId": "2c71a52f-a7cb-4cf8-9d36-9fe72eb48635"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/25\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 5s/step - accuracy: 0.9380 - loss: 0.3314 - val_accuracy: 0.9867 - val_loss: 0.0762 - learning_rate: 1.0000e-05\n",
            "Epoch 11/25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9.1 model.evaluate\n",
        "loss, acc = model.evaluate(test_ds)\n",
        "print(\"Test loss:\", loss, \"Test accuracy:\", acc)\n",
        "\n",
        "# 9.2 predictions -> classification report + confusion matrix\n",
        "import numpy as np\n",
        "y_true = np.concatenate([y.numpy() for x,y in test_ds], axis=0)\n",
        "y_pred_probs = model.predict(test_ds)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(classification_report(y_true, y_pred, target_names=classes))\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(y_true, y_pred))\n"
      ],
      "metadata": {
        "id": "viRdgmVBlM76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Save model in .keras format\n",
        "model_save_path = '/content/drive/MyDrive/civic_eye_model_final.keras'\n",
        "model.save(model_save_path)\n",
        "print(\"Saved model to:\", model_save_path)\n",
        "\n",
        "# (Optional) if you also want .h5\n",
        "# model.save('/content/drive/MyDrive/civic_eye_model_final.h5')\n"
      ],
      "metadata": {
        "id": "sTw8Ot7euMlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# ✅ Upload image(s) using file picker\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Mapping labels -> folder -> department\n",
        "label_to_folder = {i: classes[i] for i in range(len(classes))}\n",
        "label_to_department = {\n",
        "    'garbage_images': 'Department of sanitation',\n",
        "    'potholes_images': 'Department of Road and transport',\n",
        "    'sewage_drainage_images': 'Department of sewage and drainage',\n",
        "    'street_light_images': 'Department of street light'\n",
        "}\n",
        "\n",
        "def predict_image(path):\n",
        "    img = Image.open(path).convert('RGB').resize(IMG_SIZE)\n",
        "    arr = np.array(img).astype(np.float32)\n",
        "    arr = tf.keras.applications.efficientnet.preprocess_input(arr)\n",
        "    arr = np.expand_dims(arr, 0)\n",
        "\n",
        "    probs = model.predict(arr)[0]\n",
        "    idx = int(np.argmax(probs))\n",
        "    folder_name = label_to_folder[idx]\n",
        "    dept = label_to_department[folder_name]\n",
        "    return {\n",
        "        'pred_label': folder_name,\n",
        "        'department': dept,\n",
        "        'probability': float(probs[idx])\n",
        "    }\n",
        "\n",
        "# ✅ Run prediction for each uploaded file\n",
        "for fn in uploaded.keys():\n",
        "    result = predict_image(fn)\n",
        "    print(f\"\\n📷 File: {fn}\")\n",
        "    print(f\"Predicted Class: {result['pred_label']}\")\n",
        "    print(f\"Department: {result['department']}\")\n",
        "    print(f\"Confidence: {result['probability']*100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "8kvVujhkvQVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Path where you saved your model\n",
        "model_save_path = '/content/drive/MyDrive/civic_eye_model_final.keras'\n",
        "\n",
        "# Check if file exists\n",
        "if os.path.exists(model_save_path):\n",
        "    print(\"✅ Model file exists:\", model_save_path)\n",
        "    print(\"File size (MB):\", round(os.path.getsize(model_save_path) / (1024*1024), 2))\n",
        "else:\n",
        "    print(\"❌ Model file not found at:\", model_save_path)\n"
      ],
      "metadata": {
        "id": "XeCBmA9XvY0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, datetime, numpy as np\n",
        "from collections import defaultdict\n",
        "PRIORITY_DATA_DIR = DATA_DIR  # You can point this to any folder you want to score\n",
        "IMAGE_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\", \".JPG\", \".JPEG\", \".PNG\", \".WEBP\"}\n",
        "DEPT_CAPACITY = {\n",
        "    'Department of sanitation': 1.2,\n",
        "    'Department of Road and transport': 0.8,\n",
        "    'Department of sewage and drainage': 0.9,\n",
        "    'Department of street light': 1.1\n",
        "}\n",
        "\n",
        "_FALLBACK_DEPT = {\n",
        "    'garbage_images': 'Department of sanitation',\n",
        "    'Potholes_images': 'Department of Road and transport',\n",
        "    'potholes_images': 'Department of Road and transport',\n",
        "    'Sewage_drainage_images': 'Department of sewage and drainage',\n",
        "    'sewage_drainage_images': 'Department of sewage and drainage',\n",
        "    'street_light_images': 'Department of street light',\n",
        "}\n",
        "def _dept_for_label(lbl: str) -> str:\n",
        "    try:\n",
        "        return label_to_department.get(lbl, _FALLBACK_DEPT.get(lbl, 'Department of sanitation'))\n",
        "    except NameError:\n",
        "        return _FALLBACK_DEPT.get(lbl, 'Department of sanitation')\n",
        "def _file_timestamp(path: str) -> datetime.datetime:\n",
        "    try:\n",
        "        return datetime.datetime.fromtimestamp(os.path.getmtime(path))\n",
        "    except Exception:\n",
        "        return datetime.datetime.now()\n",
        "def _frequency_score(class_count: int, max_count: int) -> float:\n",
        "    if max_count <= 0:\n",
        "        return 0.0\n",
        "    norm = class_count / float(max_count)            # 0..1\n",
        "    score = np.log1p(norm * 10.0) / np.log1p(10.0) * 10.0\n",
        "    return float(np.clip(score, 0.0, 10.0))\n",
        "\n",
        "def _recency_score(timestamps) -> float:\n",
        "    if not timestamps:\n",
        "        return 0.0\n",
        "    now = datetime.datetime.now()\n",
        "    hours = [(now - ts).total_seconds() / 3600.0 for ts in timestamps if ts is not None]\n",
        "    if not hours:\n",
        "        return 0.0\n",
        "    avg_hours = float(np.mean(hours))\n",
        "    if avg_hours <= 1:   return 10.0\n",
        "    if avg_hours <= 6:   return 8.0\n",
        "    if avg_hours <= 24:  return 6.0\n",
        "    if avg_hours <= 72:  return 4.0\n",
        "    return 2.0\n",
        "\n",
        "try:\n",
        "    import cv2\n",
        "except Exception as e:\n",
        "    raise ImportError(\"OpenCV (cv2) is required for severity analysis. In Colab it's preinstalled. If local, install `opencv-python-headless`.\") from e\n",
        "class PrioritySeverityAnalyzer:\n",
        "    \"\"\"Rule-based severity scoring per image (0..10).\"\"\"\n",
        "    def __init__(self):\n",
        "        # Use normalized keys (lowercase) internally\n",
        "        self.weights = {\n",
        "            'garbage_images':             {'area_coverage': 0.4, 'color_intensity': 0.3, 'texture_roughness': 0.3},\n",
        "            'potholes_images':            {'depth_estimation': 0.5, 'area_coverage': 0.3, 'edge_sharpness': 0.2},\n",
        "            'sewage_drainage_images':     {'water_level': 0.4, 'contamination_color': 0.4, 'area_coverage': 0.2},\n",
        "            'street_light_images':        {'darkness_level': 0.6, 'time_factor': 0.4},\n",
        "        }\n",
        "\n",
        "    def _norm_type(self, t: str) -> str:\n",
        "        t = (t or \"\").strip()\n",
        "        if t.lower().startswith(\"potholes_\"): return \"potholes_images\"\n",
        "        if t.lower().startswith(\"sewage_\"):   return \"sewage_drainage_images\"\n",
        "        return t.lower()\n",
        "\n",
        "    def _safe_imread(self, path):\n",
        "        img = cv2.imread(path)\n",
        "        return img\n",
        "\n",
        "    def analyze(self, issue_type: str, image_path: str, timestamp: datetime.datetime = None) -> float:\n",
        "        key = self._norm_type(issue_type)\n",
        "        if key == \"garbage_images\":\n",
        "            return self._garbage(image_path)\n",
        "        elif key == \"potholes_images\":\n",
        "            return self._pothole(image_path)\n",
        "        elif key == \"sewage_drainage_images\":\n",
        "            return self._sewage(image_path)\n",
        "        elif key == \"street_light_images\":\n",
        "            return self._streetlight(image_path, timestamp)\n",
        "        return 5.0\n",
        "\n",
        "    def _garbage(self, path: str) -> float:\n",
        "        img = self._safe_imread(path)\n",
        "        if img is None: return 5.0\n",
        "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "        # browns / dark-grays\n",
        "        ranges = [\n",
        "            ((10, 50, 20), (20, 255, 200)),    # brownish\n",
        "            ((0, 0, 0), (180, 50, 100)),       # dark/gray\n",
        "        ]\n",
        "        total = 0\n",
        "        for lo, hi in ranges:\n",
        "            mask = cv2.inRange(hsv, np.array(lo), np.array(hi))\n",
        "            total += cv2.countNonZero(mask)\n",
        "        area_cov = total / float(img.shape[0] * img.shape[1])\n",
        "\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        color_var = float(np.var(gray))\n",
        "        color_intensity = min(color_var / 1000.0, 1.0)\n",
        "\n",
        "        edges = cv2.Canny(gray, 50, 150)\n",
        "        tex_rough = float(np.sum(edges)) / (img.shape[0] * img.shape[1] * 255.0)\n",
        "\n",
        "        w = self.weights['garbage_images']\n",
        "        score = area_cov * w['area_coverage'] + color_intensity * w['color_intensity'] + tex_rough * w['texture_roughness']\n",
        "        return float(np.clip(score * 10.0, 0.0, 10.0))\n",
        "\n",
        "    def _pothole(self, path: str) -> float:\n",
        "        img = self._safe_imread(path)\n",
        "        if img is None: return 5.0\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        edges = cv2.Canny(gray, 30, 100)\n",
        "        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        if not contours: return 1.0\n",
        "\n",
        "        largest = max(contours, key=cv2.contourArea)\n",
        "        area = float(cv2.contourArea(largest))\n",
        "        area_cov = area / float(img.shape[0] * img.shape[1])\n",
        "\n",
        "        blur = cv2.GaussianBlur(gray, (15, 15), 0)\n",
        "        _, otsu = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "        # darker = deeper (rough proxy)\n",
        "        depth_est = 1.0 - (np.sum(otsu) / (img.shape[0] * img.shape[1] * 255.0))\n",
        "\n",
        "        edge_sharp = float(np.sum(edges)) / (img.shape[0] * img.shape[1] * 255.0)\n",
        "\n",
        "        w = self.weights['potholes_images']\n",
        "        score = depth_est * w['depth_estimation'] + area_cov * w['area_coverage'] + edge_sharp * w['edge_sharpness']\n",
        "        return float(np.clip(score * 15.0, 0.0, 10.0))\n",
        "\n",
        "    def _sewage(self, path: str) -> float:\n",
        "        img = self._safe_imread(path)\n",
        "        if img is None: return 5.0\n",
        "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "        # water-ish\n",
        "        water = cv2.inRange(hsv, np.array([100, 50, 20]), np.array([130, 255, 255]))\n",
        "        water_level = cv2.countNonZero(water) / float(img.shape[0] * img.shape[1])\n",
        "\n",
        "        # contamination (greens/yellows/reds)\n",
        "        contam_ranges = [\n",
        "            ((35, 40, 40), (85, 255, 255)),   # green/yellow\n",
        "            ((0, 120, 70), (10, 255, 255)),   # reddish\n",
        "        ]\n",
        "        contam = 0\n",
        "        for lo, hi in contam_ranges:\n",
        "            mask = cv2.inRange(hsv, np.array(lo), np.array(hi))\n",
        "            contam += cv2.countNonZero(mask)\n",
        "        contam_color = contam / float(img.shape[0] * img.shape[1])\n",
        "\n",
        "        area_cov = water_level + contam_color\n",
        "        w = self.weights['sewage_drainage_images']\n",
        "        score = water_level * w['water_level'] + contam_color * w['contamination_color'] + area_cov * w['area_coverage']\n",
        "        return float(np.clip(score * 12.0, 0.0, 10.0))\n",
        "\n",
        "    def _streetlight(self, path: str, timestamp: datetime.datetime = None) -> float:\n",
        "        img = self._safe_imread(path)\n",
        "        if img is None: return 5.0\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        avg_brightness = float(np.mean(gray)) / 255.0\n",
        "        darkness = 1.0 - avg_brightness\n",
        "\n",
        "        time_factor = 1.0\n",
        "        ts = timestamp or datetime.datetime.now()\n",
        "        h = ts.hour\n",
        "        if (18 <= h <= 23) or (0 <= h <= 6):\n",
        "            time_factor = 1.5\n",
        "        elif 6 < h < 18:\n",
        "            time_factor = 0.7\n",
        "\n",
        "        w = self.weights['street_light_images']\n",
        "        score = darkness * w['darkness_level'] + (time_factor - 1.0) * w['time_factor']\n",
        "        return float(np.clip(score * 8.0, 0.0, 10.0))\n",
        "def _list_all_images(base_dir: str):\n",
        "    items = []\n",
        "    for root, _, files in os.walk(base_dir):\n",
        "        for fn in files:\n",
        "            ext = os.path.splitext(fn)[1]\n",
        "            if ext in IMAGE_EXTS:\n",
        "                path = os.path.join(root, fn)\n",
        "                items.append(path)\n",
        "    return items\n",
        "def run_priority_on_directory(base_dir: str = PRIORITY_DATA_DIR, use_model: bool = True):\n",
        "    paths = _list_all_images(base_dir)\n",
        "    if not paths:\n",
        "        print(f\"No images found under: {base_dir}\")\n",
        "        return []\n",
        "\n",
        "    # 1) Classify each image using your model (predict_image) or, fallback to folder name\n",
        "    predictions = []\n",
        "    for p in paths:\n",
        "        # fallback predicted label from folder (last subfolder under base)\n",
        "        folder_guess = os.path.basename(os.path.dirname(p))\n",
        "        if use_model:\n",
        "            try:\n",
        "                pred = predict_image(p)  # defined in YOUR code above\n",
        "                pred_label = pred.get('pred_label', folder_guess)\n",
        "                dept = pred.get('department', _dept_for_label(pred_label))\n",
        "                prob = float(pred.get('probability', 1.0))\n",
        "            except Exception:\n",
        "                pred_label, dept, prob = folder_guess, _dept_for_label(folder_guess), 1.0\n",
        "        else:\n",
        "            pred_label, dept, prob = folder_guess, _dept_for_label(folder_guess), 1.0\n",
        "\n",
        "        predictions.append({\n",
        "            \"image_path\": p,\n",
        "            \"pred_label\": pred_label,\n",
        "            \"department\": dept,\n",
        "            \"probability\": prob,\n",
        "            \"timestamp\": _file_timestamp(p),\n",
        "        })\n",
        "\n",
        "    # 2) Severity per image\n",
        "    analyzer = PrioritySeverityAnalyzer()\n",
        "    for item in predictions:\n",
        "        item[\"severity\"] = analyzer.analyze(item[\"pred_label\"], item[\"image_path\"], item[\"timestamp\"])\n",
        "\n",
        "    # 3) Group by predicted class (since no location clustering)\n",
        "    groups = defaultdict(list)\n",
        "    for it in predictions:\n",
        "        groups[it[\"pred_label\"]].append(it)\n",
        "\n",
        "    # 4) Compute priority per class\n",
        "    results = []\n",
        "    max_reports = max((len(v) for v in groups.values()), default=1)\n",
        "    for label, items in groups.items():\n",
        "        sev_vals = [it[\"severity\"] for it in items]\n",
        "        avg_sev = float(np.mean(sev_vals))\n",
        "        max_sev = float(np.max(sev_vals))\n",
        "        final_sev = max_sev if (max_sev - avg_sev) > 2.0 else avg_sev  # capture rare extreme cases\n",
        "\n",
        "        freq = _frequency_score(len(items), max_reports)\n",
        "        rec  = _recency_score([it[\"timestamp\"] for it in items])\n",
        "\n",
        "        # weights: Severity 60% + Frequency 25% + Recency 15%\n",
        "        score = final_sev * 0.60 + freq * 0.25 + rec * 0.15\n",
        "\n",
        "        # apply department capacity\n",
        "        dept = items[0][\"department\"]\n",
        "        cap = DEPT_CAPACITY.get(dept, 1.0)\n",
        "        score *= cap\n",
        "\n",
        "        # store\n",
        "        results.append({\n",
        "            \"issue_type\": label,\n",
        "            \"department\": dept,\n",
        "            \"reports\": len(items),\n",
        "            \"severity\": round(final_sev, 1),\n",
        "            \"frequency\": round(freq, 1),\n",
        "            \"recency\": round(rec, 1),\n",
        "            \"priority_score\": round(score, 2),\n",
        "            \"sample_images\": [os.path.basename(it[\"image_path\"]) for it in items[:3]],\n",
        "        })\n",
        "\n",
        "    # 5) Sort & print\n",
        "    results.sort(key=lambda r: r[\"priority_score\"], reverse=True)\n",
        "\n",
        "    print(\"\\n🏆 PRIORITY RANKING (by predicted class)\")\n",
        "    for i, r in enumerate(results, 1):\n",
        "        urgency = \"🔥 URGENT\" if r[\"priority_score\"] > 7 else (\"⚡ MEDIUM\" if r[\"priority_score\"] > 5 else \"📝 LOW\")\n",
        "        print(f\"\\n#{i} {urgency}  Score: {r['priority_score']}\")\n",
        "        print(f\"   Type: {r['issue_type']}  | Dept: {r['department']}  | Reports: {r['reports']}\")\n",
        "        print(f\"   Severity: {r['severity']}/10  | Frequency: {r['frequency']}/10  | Recency: {r['recency']}/10\")\n",
        "        if r[\"sample_images\"]:\n",
        "            print(f\"   Samples: {', '.join(r['sample_images'])}\")\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "aglauwdTxRri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "def plot_predictions_with_priority(images, y_true, y_pred, severities, priorities, class_names, n=9):\n",
        "    \"\"\"\n",
        "    Show sample predictions with True, Pred, Priority, Severity above each image.\n",
        "\n",
        "    Args:\n",
        "        images: numpy array of images (preprocessed back to 0–255 for plotting)\n",
        "        y_true: true labels (int)\n",
        "        y_pred: predicted labels (int)\n",
        "        severities: list of severity scores for each image\n",
        "        priorities: list of priority scores for each image\n",
        "        class_names: list of class label names\n",
        "        n: number of images to plot\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    idxs = random.sample(range(len(images)), min(n, len(images)))\n",
        "\n",
        "    for i, idx in enumerate(idxs):\n",
        "        plt.subplot(3, 3, i+1)\n",
        "        plt.imshow(images[idx].astype(\"uint8\"))\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        true_lbl = class_names[y_true[idx]]\n",
        "        pred_lbl = class_names[y_pred[idx]]\n",
        "        sev = severities[idx] if severities else \"NA\"\n",
        "        pri = priorities[idx] if priorities else \"NA\"\n",
        "\n",
        "        color = \"green\" if true_lbl == pred_lbl else \"red\"\n",
        "        title = f\"True: {true_lbl}\\nPred: {pred_lbl}\\nPriority: {pri}\\nSeverity: {sev}\"\n",
        "        plt.title(title, fontsize=10, color=color)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "b3-WleiOhbCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage after predictions\n",
        "y_true = np.concatenate([y.numpy() for x, y in test_ds], axis=0)\n",
        "y_pred_probs = model.predict(test_ds)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# Dummy severity & priority (replace with your analyzer results)\n",
        "severities = [round(random.uniform(1, 10), 1) for _ in range(len(y_true))]\n",
        "priorities = [round(random.uniform(1, 10), 1) for _ in range(len(y_true))]\n",
        "\n",
        "# To visualize, fetch some raw images (from filepaths instead of test_ds)\n",
        "sample_imgs = [plt.imread(p) for p in filepaths[:len(y_true)]]\n",
        "\n",
        "plot_predictions_with_priority(sample_imgs, y_true, y_pred, severities, priorities, classes, n=9)\n"
      ],
      "metadata": {
        "id": "ok187JSWhd-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =================== PRIORITY EVALUATION ON TEST SET ===================\n",
        "import os, datetime, numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from PIL import Image\n",
        "\n",
        "# --- Helpers (reuse from your priority cell if already defined) ---\n",
        "def file_timestamp(path: str) -> datetime.datetime:\n",
        "    try:\n",
        "        return datetime.datetime.fromtimestamp(os.path.getmtime(path))\n",
        "    except Exception:\n",
        "        return datetime.datetime.now()\n",
        "\n",
        "def freq_score(count, max_count):\n",
        "    if max_count <= 0: return 0.0\n",
        "    norm = count / float(max_count)\n",
        "    score = np.log1p(norm * 10.0) / np.log1p(10.0) * 10.0\n",
        "    return float(np.clip(score, 0.0, 10.0))\n",
        "\n",
        "def recency_score(timestamps):\n",
        "    if not timestamps: return 0.0\n",
        "    now = datetime.datetime.now()\n",
        "    hours = [(now - ts).total_seconds()/3600.0 for ts in timestamps if ts is not None]\n",
        "    if not hours: return 0.0\n",
        "    avg = float(np.mean(hours))\n",
        "    if avg <= 1:   return 10.0\n",
        "    if avg <= 6:   return 8.0\n",
        "    if avg <= 24:  return 6.0\n",
        "    if avg <= 72:  return 4.0\n",
        "    return 2.0\n",
        "\n",
        "# --- Safe mapping between label strings and indices (handles case differences) ---\n",
        "def label_str_to_idx(lbl: str):\n",
        "    try:\n",
        "        return classes.index(lbl)\n",
        "    except ValueError:\n",
        "        low = [c.lower() for c in classes]\n",
        "        if lbl.lower() in low:\n",
        "            return low.index(lbl.lower())\n",
        "        # fallback: unknown -> 0\n",
        "        return 0\n",
        "\n",
        "# --- Main runner on X_test / y_test ---\n",
        "def run_priority_on_test_set(show_grid=True, grid_n=9, apply_capacity=True):\n",
        "    if 'X_test' not in globals() or 'y_test' not in globals():\n",
        "        raise RuntimeError(\"X_test / y_test not found. Run your train/val/test split cell first.\")\n",
        "    if 'PrioritySeverityAnalyzer' not in globals():\n",
        "        raise RuntimeError(\"PrioritySeverityAnalyzer not found. Paste the priority module first.\")\n",
        "    if 'predict_image' not in globals():\n",
        "        raise RuntimeError(\"predict_image(...) not found. Keep your classification inference cell.\")\n",
        "\n",
        "    analyzer = PrioritySeverityAnalyzer()\n",
        "\n",
        "    # 1) Per-image inference on test set\n",
        "    pred_idx = []\n",
        "    pred_label = []\n",
        "    dept_list = []\n",
        "    timestamps = []\n",
        "    severities = []\n",
        "\n",
        "    for p in X_test:\n",
        "        ts = file_timestamp(p)\n",
        "        pr = predict_image(p)  # uses your trained model\n",
        "        lbl = pr.get('pred_label')\n",
        "        dpt = pr.get('department', _FALLBACK_DEPT.get(lbl, 'Department of sanitation'))\n",
        "\n",
        "        s = analyzer.analyze(lbl, p, ts)\n",
        "\n",
        "        pred_label.append(lbl)\n",
        "        pred_idx.append(label_str_to_idx(lbl))\n",
        "        dept_list.append(dpt)\n",
        "        timestamps.append(ts)\n",
        "        severities.append(float(s))\n",
        "\n",
        "    pred_idx = np.array(pred_idx)\n",
        "    # 2) Classification accuracy on test set\n",
        "    clf_acc = float((pred_idx == y_test).mean()) if len(y_test) > 0 else 0.0\n",
        "    print(f\"\\n✅ Classification accuracy on test set: {clf_acc:.4f}\")\n",
        "\n",
        "    # 3) Frequency & recency per predicted class (from test set only)\n",
        "    by_class = defaultdict(list)\n",
        "    for i, lbl in enumerate(pred_label):\n",
        "        by_class[lbl].append(i)\n",
        "\n",
        "    max_reports = max((len(v) for v in by_class.values()), default=1)\n",
        "\n",
        "    class_freq = {}\n",
        "    class_rec  = {}\n",
        "    for lbl, idxs in by_class.items():\n",
        "        class_freq[lbl] = freq_score(len(idxs), max_reports)\n",
        "        class_rec[lbl]  = recency_score([timestamps[i] for i in idxs])\n",
        "\n",
        "    # 4) Per-image priority score (uses image severity + class freq/recency)\n",
        "    priority_scores = []\n",
        "    for i, lbl in enumerate(pred_label):\n",
        "        sev = severities[i]\n",
        "        fs  = class_freq[lbl]\n",
        "        rs  = class_rec[lbl]\n",
        "        score = 0.60*sev + 0.25*fs + 0.15*rs\n",
        "        if apply_capacity:\n",
        "            cap = DEPT_CAPACITY.get(dept_list[i], 1.0)\n",
        "            score *= cap\n",
        "        priority_scores.append(round(score, 2))\n",
        "\n",
        "    # 5) Aggregate table per class (like your ranking)\n",
        "    rows = []\n",
        "    for lbl, idxs in by_class.items():\n",
        "        sev_vals = [severities[i] for i in idxs]\n",
        "        avg_sev = float(np.mean(sev_vals))\n",
        "        max_sev = float(np.max(sev_vals))\n",
        "        final_sev = max_sev if (max_sev - avg_sev) > 2.0 else avg_sev\n",
        "        freq_val = class_freq[lbl]\n",
        "        rec_val  = class_rec[lbl]\n",
        "        dept = dept_list[idxs[0]]\n",
        "        score = 0.60*final_sev + 0.25*freq_val + 0.15*rec_val\n",
        "        if apply_capacity:\n",
        "            score *= DEPT_CAPACITY.get(dept, 1.0)\n",
        "        rows.append({\n",
        "            \"issue_type\": lbl,\n",
        "            \"department\": dept,\n",
        "            \"reports\": len(idxs),\n",
        "            \"severity\": round(final_sev,1),\n",
        "            \"frequency\": round(freq_val,1),\n",
        "            \"recency\": round(rec_val,1),\n",
        "            \"priority_score\": round(score,2),\n",
        "        })\n",
        "\n",
        "    rows.sort(key=lambda r: r[\"priority_score\"], reverse=True)\n",
        "\n",
        "    print(\"\\n🏆 PRIORITY RANKING on TEST SET (by predicted class)\")\n",
        "    for i, r in enumerate(rows, 1):\n",
        "        urgency = \"🔥 URGENT\" if r[\"priority_score\"] > 7 else (\"⚡ MEDIUM\" if r[\"priority_score\"] > 5 else \"📝 LOW\")\n",
        "        print(f\"\\n#{i} {urgency}  Score: {r['priority_score']}\")\n",
        "        print(f\"   Type: {r['issue_type']}  | Dept: {r['department']}  | Reports: {r['reports']}\")\n",
        "        print(f\"   Severity: {r['severity']}/10  | Frequency: {r['frequency']}/10  | Recency: {r['recency']}/10\")\n",
        "\n",
        "    # 6) Optional: grid viz with True/Pred/Priority/Severity\n",
        "    if show_grid:\n",
        "        n = min(grid_n, len(X_test))\n",
        "        idxs = np.random.choice(len(X_test), size=n, replace=False)\n",
        "        cols = int(np.ceil(np.sqrt(n)))\n",
        "        rows_plots = int(np.ceil(n / cols))\n",
        "        plt.figure(figsize=(4*cols, 4*rows_plots))\n",
        "        for k, i in enumerate(idxs):\n",
        "            img = Image.open(X_test[i]).convert('RGB')\n",
        "            plt.subplot(rows_plots, cols, k+1)\n",
        "            plt.imshow(img)\n",
        "            plt.axis('off')\n",
        "            true_lbl = classes[y_test[i]]\n",
        "            pred_lbl = pred_label[i]\n",
        "            sev = round(severities[i], 1)\n",
        "            pri = priority_scores[i]\n",
        "            color = \"green\" if label_str_to_idx(pred_lbl) == y_test[i] else \"red\"\n",
        "            title = f\"True: {true_lbl}\\nPred: {pred_lbl}\\nPriority: {pri}\\nSeverity: {sev}\"\n",
        "            plt.title(title, fontsize=10, color=color)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    # Return detailed per-image results\n",
        "    results = []\n",
        "    for i, p in enumerate(X_test):\n",
        "        results.append({\n",
        "            \"image_path\": p,\n",
        "            \"true_label\": classes[y_test[i]],\n",
        "            \"pred_label\": pred_label[i],\n",
        "            \"department\": dept_list[i],\n",
        "            \"severity\": round(float(severities[i]), 2),\n",
        "            \"priority_score\": priority_scores[i],\n",
        "            \"timestamp\": timestamps[i].isoformat(timespec='seconds'),\n",
        "        })\n",
        "\n",
        "    return {\n",
        "        \"classification_accuracy\": clf_acc,\n",
        "        \"per_class_priority\": rows,\n",
        "        \"per_image_results\": results,\n",
        "    }\n",
        "\n",
        "# -------- Run it --------\n",
        "priority_test_results = run_priority_on_test_set(show_grid=True, grid_n=9, apply_capacity=True)\n"
      ],
      "metadata": {
        "id": "jYQWGNmShlNG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}